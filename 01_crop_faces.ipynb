{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungSong99/gender-recognition/blob/main/01_crop_faces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "ExecuteTime": {
          "end_time": "2025-03-03T03:02:43.624596Z",
          "start_time": "2025-03-03T03:02:43.619706Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "adb0bb8db71d0fdf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T03:02:44.040545Z",
          "start_time": "2025-03-03T03:02:44.005439Z"
        },
        "id": "adb0bb8db71d0fdf"
      },
      "outputs": [],
      "source": [
        "# extract the images path from folder\n",
        "fpath = glob('data/female/*.jpg')\n",
        "mpath = glob('data/male/*.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of images in Female folder: 0\n",
            "The number of images in Male folder: 0\n"
          ]
        }
      ],
      "source": [
        "print(f'The number of images in Female folder: {len(fpath)}')\n",
        "print(f'The number of images in Male folder: {len(mpath)}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T03:02:44.796731Z",
          "start_time": "2025-03-03T03:02:44.790824Z"
        },
        "id": "7edbbf3fb5412c95",
        "outputId": "09af7340-1598-4570-91ff-5a278400030c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7edbbf3fb5412c95",
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4cSHnI7uEcNA"
      },
      "id": "4cSHnI7uEcNA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "haar = cv2.CascadeClassifier('model/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T03:02:45.378166Z",
          "start_time": "2025-03-03T03:02:45.361968Z"
        },
        "id": "5f2f6984e142ee12"
      },
      "id": "5f2f6984e142ee12",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image-0 processed\n",
            "image-1 processed\n",
            "image-2 processed\n",
            "image-3 processed\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(fpath)):\n",
        "    try:\n",
        "        if i == 5:\n",
        "            break\n",
        "\n",
        "        # 1 - Read images\n",
        "        img = cv2.imread(fpath[i])\n",
        "\n",
        "        # 2 - Apply Haar Cascade\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        face_list = haar.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "        image = img.copy()\n",
        "\n",
        "        for x, y, w, h in face_list:\n",
        "            # 3 - crop face\n",
        "            roi = image[y:y+h, x:x+w]\n",
        "            # 4 - save image\n",
        "            cv2.imwrite(f'crop_data/female/female_{i}.jpg', roi)\n",
        "            print(f'image-{i} processed')\n",
        "\n",
        "    except:\n",
        "        print(f'Unable to Process the image-{i}')\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-03T03:03:16.207334Z",
          "start_time": "2025-03-03T03:03:16.185860Z"
        },
        "id": "9da2e3f5c6b168db",
        "outputId": "04beaac1-0f46-4120-98af-771d93bca8f9"
      },
      "id": "9da2e3f5c6b168db",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "e01abe4757a1bee6"
      },
      "id": "e01abe4757a1bee6",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "face_recognition",
      "language": "python",
      "display_name": "Python (face_recognition)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}